---
title: 幀(Frame) 與 時間戳(Timestamp)
description: 幀的基本結構與它在傳輸流程中的定位。
authros: yhchen
tags: 
  - streaming
date: 2025-12-08
---

音訊與視訊的資料型態雖然不同，但在所有現代串流技術中，它們遵循同一套邏輯：資料以 Frame 為最小單位、時間以 timestamp 表示、兩者配合播放器的時脈建立同步。

<!-- truncate -->

## 視訊幀(Video Frame)

影像幀是一個靜態畫面。編碼器、播放器、容器格式都以 Frame 作為處理單位。實務上，一個 Frame 具有以下資訊：

影像幀內容：

- 尺寸與像素格式（例如 YUV420）
- 播放順序時間（PTS）
- 解碼順序時間（DTS，有些格式才需要）
- 是否為關鍵畫面（I-frame）或預測畫面

Frame 本身不帶「秒數」，只帶 timestamp。秒數是由「timestamp ÷ timebase」換算出來。

例：一個 H264 stream 的時間基常見為 1 / 9K。若某 Frame 的 Timestamp 是 18K，代表它應在「18K / 9K = 2 秒」播放。

## 音訊幀(Audio Frame)

音訊幀是一段固定長度的取樣資料。聲音在時間軸上是連續的訊號，因此編碼前會先被切成多段，每段形成一個 Audio Frame。每個音訊編碼器會定義自己的 frame duration，例如 AAC 常見 1024 samples，Opus 常見 20ms 或 60ms。這些都會反映在 timestamp 的連續性上。

音訊幀內容：

- 一段樣本序列（PCM 或編碼後的 bitstream）
- 取樣率與 channel layout
- 播放時間戳（PTS）
- 編碼器內部需要的附加資訊，例如 Opus 的 TOC byte

## 時間戳(Timestamp) 與 時基(Timebase)

Timestamp 是一個遞增的整數。它本身沒有意義，需要 timebase 才能換算為秒數。timebase 通常由編碼器、容器或 RTP profile 定義。不同階段可能使用不同的 timebase：

- H264 NALU 在 Annex B 階段沒有時間資訊
- 封裝到 MP4 時會被賦予 timebase，例如 1/90000
- RTP 傳輸同樣使用 90kHz 作為 video timestamp 的基準

若兩個系統的 timebase 不一致，就需要在重封裝時重新計算 timestamp，使播放時序維持一致。

:::tip

時刻 (Timescale) 與時基 (Timebase) 是一個精確且穩定的時間參考。其含意是將1秒劃分為幾個刻度，比方說 Timescale = `90000`，則 Timebase = `1 / 90000`，如果某個幀的時戳為 3600，則必須在第 `3600 * Timebase` 秒顯示。

時基是非常重要的，如果直接以採樣率 SR 進行換算，常見的 SR 為 24 , 25 , 30。只要 `1 / SR` 的結果是無限小數循環，使用 `float` 與 `double` 都會有微小的誤差，當播放的影片時間足夠長，就會導致音訊與視訊的漂移(不同步)。以 90000 來說，他是常見的採樣率的公倍數，使得音視訊可以在整數域上進行計算，避免失真。

:::

## PTS 與 DTS

PTS 表示播放順序。DTS 表示解碼順序。存在 B-frame(雙向預測幀) 的編碼器會遇到「解碼順序與播放順序不一致」的情況，因此 DTS 會落後於 PTS。沒有 B-frame 的低延遲設定不需要 DTS，播放器可直接依 PTS 進行排程。這是因為 B-Frame 同時參考了前一幀與後一幀的資訊，因此解碼順序與播放順序可能會不一樣。

例：在一段含 B-frame 的流中：

- Frame 1：I-frame
- Frame 2：B-frame
- Frame 3：P-frame

解碼順序是 1 → 3 → 2，播放順序是 1 → 2 → 3。PTS/DTS 用來解決這個差異，避免播放器錯誤排序導致畫面停頓。

## Frame 與 Container 的關係

Frame 在容器格式中被放進對應的封包。例如：

- 在 TS 中是 PES packet。
- 在 MP4 中會形成 sample 並被索引到對應的 track。
- 在 WebM/Matroska 中則是 Block 內的單一 frame。

容器不會改變 frame 的內容，但會重新賦予時間資訊，例如：

- sample duration
- composition time offset（解決 B-frame 重排）
- decode time

重封裝時，timestamp 處理是必要工作。例如把 Annex B H264 封裝進 fMP4，需要重建 sample duration 與 composition time offset，否則播放器無法正確播放。

RTP 不直接傳 Frame，而是將 Frame 拆成多個 RTP packets。每個 packet 帶相同 timestamp，代表它們屬於同一個 Frame。marker bit 通常在最後一個 packet 設定，用來指示 frame boundary。

RTP timestamp 不等於編碼器原始 timestamp。它是以 RFC 規範的 clock rate 遞增：

- Video：90kHz
- Audio（Opus）：48kHz
- Audio（AAC）：取樣率

若在轉封裝到 RTP 時，沒有正確換算 timestamp，接收端會遭遇 jitter、播放延遲累積或同步錯位。

## 可能發生的錯誤

### Audio/Video 不同步

影像 timestamp 使用 timebase A，音訊使用 timebase B，但兩者沒有換算成共同 timebase 。播放器無法對齊，會表現成「音提早」或「畫面落後」。

### B-frame 設定錯誤

若封裝時錯置 composition time offset，B-frame 流會直接破損，例如畫面抖動、播放順序錯亂。
